'use client'

import { useState, useRef, useEffect, useCallback } from 'react'
import { Modal } from './modal'
import { Button } from './button'
import { Textarea } from './textarea'
import { Select } from './select'
import { Mic, FileText, Trash2, Square, Activity } from 'lucide-react'

interface AudioRecordingModalProps {
  isOpen: boolean
  onClose: () => void
  patientId: string
  clinicId?: string
  staffId?: string
}

export function AudioRecordingModal({ isOpen, onClose, patientId, clinicId, staffId }: AudioRecordingModalProps) {
  const [transcription, setTranscription] = useState('')
  const [selectedTemplate, setSelectedTemplate] = useState<string>('soap')
  const [summary, setSummary] = useState('')
  const [isSummarizing, setIsSummarizing] = useState(false)
  const [isRecording, setIsRecording] = useState(false)
  const [interimText, setInterimText] = useState('')

  // ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆç”¨
  const [isMicTesting, setIsMicTesting] = useState(false)
  const [micLevel, setMicLevel] = useState(0)
  const [micDeviceName, setMicDeviceName] = useState('')
  const micStreamRef = useRef<MediaStream | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const animFrameRef = useRef<number>(0)

  // è¨ºæ–­ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç”¨
  const [sttEvents, setSttEvents] = useState<string[]>([])
  const [restartDisplay, setRestartDisplay] = useState(0)

  const recognitionRef = useRef<any>(null)
  const wantRecordingRef = useRef(false)
  const toggleButtonRef = useRef<HTMLButtonElement>(null)
  const restartCountRef = useRef(0)

  // ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹
  const startMicTest = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      micStreamRef.current = stream

      const audioTrack = stream.getAudioTracks()[0]
      const trackInfo = `${audioTrack.label || 'ä¸æ˜'} (${audioTrack.readyState}, muted=${audioTrack.muted})`
      setMicDeviceName(trackInfo)

      const audioContext = new AudioContext()
      // Chrome: AudioContextãŒsuspendedçŠ¶æ…‹ã®å ´åˆresumeãŒå¿…è¦
      if (audioContext.state === 'suspended') {
        await audioContext.resume()
      }
      const analyser = audioContext.createAnalyser()
      analyser.fftSize = 256
      const source = audioContext.createMediaStreamSource(stream)
      // source â†’ analyser â†’ gain(0) â†’ destination ã§éŸ³å£°å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Œæˆã•ã›ã‚‹
      // ï¼ˆdestinationã«æ¥ç¶šã—ãªã„ã¨ChromeãŒAnalyserNodeã‚’å‡¦ç†ã—ãªã„å ´åˆãŒã‚ã‚‹ï¼‰
      const gainNode = audioContext.createGain()
      gainNode.gain.value = 0 // ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‹ã‚‰éŸ³ã‚’å‡ºã•ãªã„
      source.connect(analyser)
      analyser.connect(gainNode)
      gainNode.connect(audioContext.destination)
      audioContextRef.current = audioContext

      setIsMicTesting(true)
      console.log('[MicTest] stream active:', stream.active, 'track:', trackInfo, 'audioContext:', audioContext.state)

      const dataArray = new Uint8Array(analyser.frequencyBinCount)
      const updateLevel = () => {
        analyser.getByteFrequencyData(dataArray)
        const avg = dataArray.reduce((a, b) => a + b, 0) / dataArray.length
        setMicLevel(Math.round(avg / 255 * 100))
        animFrameRef.current = requestAnimationFrame(updateLevel)
      }
      updateLevel()
    } catch (err) {
      alert('ãƒã‚¤ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸ: ' + err)
    }
  }, [])

  // ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆåœæ­¢
  const stopMicTest = useCallback(() => {
    if (animFrameRef.current) cancelAnimationFrame(animFrameRef.current)
    if (micStreamRef.current) micStreamRef.current.getTracks().forEach(t => t.stop())
    if (audioContextRef.current) audioContextRef.current.close()
    micStreamRef.current = null
    audioContextRef.current = null
    setIsMicTesting(false)
    setMicLevel(0)
  }, [])

  // éŒ²éŸ³ã‚’åœæ­¢ã™ã‚‹å†…éƒ¨é–¢æ•°
  const doStopRef = useRef(() => {
    wantRecordingRef.current = false
    restartCountRef.current = 0
    if (recognitionRef.current) {
      try { recognitionRef.current.stop() } catch {}
    }
    setIsRecording(false)
    setInterimText('')
    setSttEvents([])
    setRestartDisplay(0)
  })

  // SpeechRecognitionã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ï¼ˆgetUserMediaä¸è¦ - SpeechRecognitionãŒç›´æ¥ãƒã‚¤ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ï¼‰
  const startRecognitionSession = useRef(() => {
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
    if (!SpeechRecognition) return

    if (recognitionRef.current) {
      try { recognitionRef.current.abort() } catch {}
      recognitionRef.current = null
    }

    const recognition = new SpeechRecognition()
    recognition.lang = 'ja-JP'
    recognition.continuous = true
    recognition.interimResults = true
    recognition.maxAlternatives = 1

    recognition.onstart = () => {
      console.log('[STT] onstart')
      setSttEvents(prev => [...prev.slice(-8), 'â³ onstart - èªè­˜é–‹å§‹'])
    }
    recognition.onaudiostart = () => {
      console.log('[STT] onaudiostart - ãƒã‚¤ã‚¯éŸ³å£°å—ä¿¡é–‹å§‹')
      setSttEvents(prev => [...prev.slice(-8), 'âœ… onaudiostart - ãƒã‚¤ã‚¯å—ä¿¡ä¸­'])
    }
    recognition.onspeechstart = () => {
      console.log('[STT] onspeechstart - éŸ³å£°æ¤œå‡º')
      setSttEvents(prev => [...prev.slice(-8), 'âœ… onspeechstart - éŸ³å£°æ¤œå‡º!'])
    }
    recognition.onspeechend = () => {
      console.log('[STT] onspeechend')
      setSttEvents(prev => [...prev.slice(-8), 'â¹ onspeechend'])
    }
    recognition.onaudioend = () => {
      console.log('[STT] onaudioend')
      setSttEvents(prev => [...prev.slice(-8), 'â¹ onaudioend'])
    }

    recognition.onresult = (event: any) => {
      console.log('[STT] onresult - results:', event.results.length)
      let interim = ''
      let finalTranscript = ''
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i]
        if (result.isFinal) {
          finalTranscript += result[0].transcript
          console.log('[STT] final:', result[0].transcript)
        } else {
          interim += result[0].transcript
        }
      }
      if (finalTranscript) {
        setTranscription(prev => prev + (prev ? '\n' : '') + finalTranscript)
        setInterimText('')
        // éŸ³å£°èªè­˜ãŒæˆåŠŸã—ãŸã‚‰ãƒªã‚¹ã‚¿ãƒ¼ãƒˆã‚«ã‚¦ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
        restartCountRef.current = 0
      } else if (interim) {
        setInterimText(interim)
      }
    }

    recognition.onerror = (event: any) => {
      console.error('[STT] onerror:', event.error)
      setSttEvents(prev => [...prev.slice(-8), `âŒ onerror: ${event.error}`])
      if (event.error === 'not-allowed') {
        alert('ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚')
        doStopRef.current()
      }
      if (event.error !== 'no-speech' && event.error !== 'aborted') {
        doStopRef.current()
      }
    }

    recognition.onend = () => {
      console.log('[STT] onend - wantRecording:', wantRecordingRef.current, 'restartCount:', restartCountRef.current)
      // çµ‚äº†ã—ãŸèªè­˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¸ã®å‚ç…§ã‚’ã‚¯ãƒªã‚¢
      recognitionRef.current = null

      if (wantRecordingRef.current) {
        // no-speeché€£ç¶šãƒªã‚¹ã‚¿ãƒ¼ãƒˆã‚’åˆ¶é™ï¼ˆæœ€å¤§20å› = ç´„2åˆ†ï¼‰
        if (restartCountRef.current >= 20) {
          console.log('[STT] ãƒªã‚¹ã‚¿ãƒ¼ãƒˆä¸Šé™åˆ°é”ã€æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ...')
          restartCountRef.current = 0
        }
        restartCountRef.current++
        setRestartDisplay(restartCountRef.current)
        setSttEvents(prev => [...prev.slice(-8), `ğŸ”„ è‡ªå‹•å†èµ·å‹• #${restartCountRef.current}`])
        console.log('[STT] è‡ªå‹•å†èµ·å‹• #' + restartCountRef.current + ' - ãƒã‚¤ã‚¯ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥å¾Œã«æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³')
        // getUserMediaã§ä¸€ç¬ãƒã‚¤ã‚¯ã‚’èµ·ã“ã—ã¦ã‹ã‚‰SpeechRecognitioné–‹å§‹
        // ï¼ˆChrome: no-speechå¾Œã«ãƒã‚¤ã‚¯ãŒã‚¹ãƒªãƒ¼ãƒ—ã™ã‚‹å•é¡Œã¸ã®å¯¾ç­–ï¼‰
        navigator.mediaDevices.getUserMedia({ audio: true })
          .then(stream => {
            // ãƒã‚¤ã‚¯ã‚’å³åº§ã«è§£æ”¾ï¼ˆSpeechRecognitionã¨ç«¶åˆã•ã›ãªã„ï¼‰
            stream.getTracks().forEach(t => t.stop())
            console.log('[STT] ãƒã‚¤ã‚¯ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥å®Œäº†ã€æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹')
            if (!wantRecordingRef.current) return
            startRecognitionSession.current()
          })
          .catch(() => {
            // getUserMediaå¤±æ•—ã§ã‚‚SpeechRecognitioné–‹å§‹ã‚’è©¦ã¿ã‚‹
            console.log('[STT] ãƒã‚¤ã‚¯ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥å¤±æ•—ã€ç›´æ¥é–‹å§‹')
            if (!wantRecordingRef.current) return
            startRecognitionSession.current()
          })
        return
      }
      setIsRecording(false)
      setInterimText('')
    }

    recognitionRef.current = recognition

    try {
      recognition.start()
      console.log('[STT] recognition.start() å®Œäº†')
    } catch (e) {
      console.error('[STT] startå¤±æ•—:', e)
      doStopRef.current()
    }
  })

  // éŒ²éŸ³é–‹å§‹: SpeechRecognitionãŒç›´æ¥ãƒã‚¤ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆgetUserMediaä¸è¦ï¼‰
  const doStartRef = useRef(() => {
    console.log('[STT] startRecording')

    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
    if (!SpeechRecognition) {
      alert('ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚Chrome ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚')
      return
    }

    wantRecordingRef.current = true
    restartCountRef.current = 0
    setIsRecording(true)
    startRecognitionSession.current()
  })

  // ãƒã‚¤ãƒ†ã‚£ãƒ–DOMã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã§ãƒˆã‚°ãƒ«åˆ¶å¾¡
  // Reactã®åˆæˆã‚¤ãƒ™ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’å®Œå…¨ã«ãƒã‚¤ãƒ‘ã‚¹
  useEffect(() => {
    if (!isOpen) return
    const button = toggleButtonRef.current
    if (!button) return

    // useEffectå†…ã®ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ï¼ˆReactã®å†ãƒ¬ãƒ³ãƒ€ãƒ¼ã«å½±éŸ¿ã•ã‚Œãªã„ï¼‰
    let startedAt = 0
    let lastBlockedAt = 0 // ãƒ€ãƒ–ãƒ«ã‚¿ãƒƒãƒ—æ¤œå‡ºç”¨

    const handler = (e: PointerEvent) => {
      if (e.button !== 0) return
      e.stopPropagation()
      e.preventDefault()

      const now = Date.now()
      const sinceStart = now - startedAt
      console.log('[STT] pointerdown: trusted=' + e.isTrusted + ' wantRec=' + wantRecordingRef.current + ' sinceStart=' + sinceStart + 'ms')

      // untrustedã‚¤ãƒ™ãƒ³ãƒˆï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ç”Ÿæˆï¼‰ã¯ç„¡è¦–
      if (!e.isTrusted) {
        console.log('[STT] untrusted event â†’ ç„¡è¦–')
        return
      }

      if (wantRecordingRef.current) {
        // éŒ²éŸ³é–‹å§‹å¾Œ10ç§’ä»¥å†…ã®phantomå¯¾ç­–
        // ãŸã ã—å‰å›ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰1ç§’ä»¥å†…ã®å†ã‚¿ãƒƒãƒ—ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³çš„ãƒ€ãƒ–ãƒ«ã‚¿ãƒƒãƒ—ï¼‰ã¯è¨±å¯
        if (startedAt > 0 && sinceStart < 10000) {
          if (lastBlockedAt > 0 && now - lastBlockedAt < 1000) {
            // ãƒ€ãƒ–ãƒ«ã‚¿ãƒƒãƒ—æ¤œå‡º â†’ åœæ­¢ã‚’è¨±å¯
            console.log('[STT] ãƒ€ãƒ–ãƒ«ã‚¿ãƒƒãƒ—æ¤œå‡º â†’ åœæ­¢ (' + sinceStart + 'ms)')
          } else {
            // åˆå›ã‚¿ãƒƒãƒ— â†’ ãƒ–ãƒ­ãƒƒã‚¯
            lastBlockedAt = now
            console.log('[STT] cooldownä¸­ â†’ åœæ­¢ã‚’ç„¡è¦– (' + sinceStart + 'ms) â€»ã‚‚ã†ä¸€åº¦æŠ¼ã™ã¨åœæ­¢')
            return
          }
        }
        console.log('[STT] toggle â†’ åœæ­¢ (native)')
        doStopRef.current()
        startedAt = 0
        lastBlockedAt = 0
      } else {
        console.log('[STT] toggle â†’ é–‹å§‹ (native)')
        startedAt = now
        lastBlockedAt = 0
        doStartRef.current()
      }
    }

    button.addEventListener('pointerdown', handler)
    return () => button.removeEventListener('pointerdown', handler)
  }, [isOpen])

  const generateSummary = async () => {
    if (!transcription.trim()) {
      alert('ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„')
      return
    }

    setIsSummarizing(true)
    try {
      const response = await fetch('/api/summarize', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          text: transcription,
          templateId: selectedTemplate,
          clinicId,
          operatorId: staffId,
        })
      })

      if (!response.ok) throw new Error('è¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸ')

      const result = await response.json()
      setSummary(result.summary)
    } catch (error) {
      console.error('è¦ç´„ã‚¨ãƒ©ãƒ¼:', error)
      alert('è¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚')
    } finally {
      setIsSummarizing(false)
    }
  }

  // ãƒ¢ãƒ¼ãƒ€ãƒ«ãŒé–‰ã˜ãŸæ™‚ã«ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆã‚‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    if (!isOpen) {
      stopMicTest()
    }
  }, [isOpen, stopMicTest])

  const clearAll = () => {
    doStopRef.current()
    stopMicTest()
    setTranscription('')
    setSummary('')
    setInterimText('')
  }

  const attachToSubKarte = async () => {
    try {
      const response = await fetch('/api/subkarte', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          patientId,
          type: 'text',
          content: summary,
          metadata: {
            source: 'audio_recording',
            template: selectedTemplate,
            transcription,
          }
        })
      })

      if (!response.ok) throw new Error('ã‚µãƒ–ã‚«ãƒ«ãƒ†ã¸ã®è²¼ã‚Šä»˜ã‘ã«å¤±æ•—ã—ã¾ã—ãŸ')

      alert('ã‚µãƒ–ã‚«ãƒ«ãƒ†ã«è²¼ã‚Šä»˜ã‘ã¾ã—ãŸ')
      onClose()
    } catch (error) {
      console.error('ã‚µãƒ–ã‚«ãƒ«ãƒ†è²¼ã‚Šä»˜ã‘ã‚¨ãƒ©ãƒ¼:', error)
      alert('ã‚µãƒ–ã‚«ãƒ«ãƒ†ã¸ã®è²¼ã‚Šä»˜ã‘ã«å¤±æ•—ã—ã¾ã—ãŸ')
    }
  }

  const sendToActivity = () => {
    alert('ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã«é€ä¿¡ã—ã¾ã—ãŸ')
    onClose()
  }

  return (
    <Modal isOpen={isOpen} onClose={onClose} className="w-[1400px] max-w-[90vw]">
      <div className="flex h-[600px]">
        {/* å·¦ãƒ‘ãƒãƒ«: ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ› */}
        <div className="flex-1 border-r border-gray-200 p-6 flex flex-col">
          <div className="flex items-center justify-between mb-3">
            <h3 className="text-lg font-semibold">ä¼šè©±å†…å®¹</h3>
            <div className="flex items-center gap-2">
              <Button
                ref={toggleButtonRef}
                className={isRecording
                  ? "bg-gray-700 hover:bg-gray-800 text-white px-4 py-1 animate-pulse"
                  : "bg-red-500 hover:bg-red-600 text-white px-4 py-1"
                }
                size="sm"
              >
                {isRecording ? (
                  <><Square className="w-4 h-4 mr-1" />éŒ²éŸ³åœæ­¢</>
                ) : (
                  <><Mic className="w-4 h-4 mr-1" />éŒ²éŸ³é–‹å§‹</>
                )}
              </Button>
              <Button
                onClick={clearAll}
                variant="outline"
                size="sm"
                disabled={!transcription && !summary}
                className="px-3 py-1"
              >
                <Trash2 className="w-4 h-4 mr-1" />
                å…¨ã‚¯ãƒªã‚¢
              </Button>
            </div>
          </div>

          {/* ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆãƒ‘ãƒãƒ« */}
          {isMicTesting && (
            <div className="mb-3 bg-green-50 border border-green-200 rounded p-3">
              <div className="flex items-center justify-between mb-2">
                <span className="text-sm font-medium text-green-800">ğŸ¤ ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆä¸­</span>
                <Button onClick={stopMicTest} variant="outline" size="sm" className="text-xs px-2 py-0.5">
                  ãƒ†ã‚¹ãƒˆçµ‚äº†
                </Button>
              </div>
              <div className="text-xs text-green-700 mb-1">ãƒ‡ãƒã‚¤ã‚¹: {micDeviceName}</div>
              <div className="w-full bg-gray-200 rounded h-5 overflow-hidden">
                <div
                  className={`h-5 rounded transition-all duration-75 ${micLevel > 30 ? 'bg-green-500' : micLevel > 5 ? 'bg-yellow-400' : 'bg-gray-400'}`}
                  style={{ width: `${Math.min(micLevel, 100)}%` }}
                />
              </div>
              <div className="flex justify-between text-xs text-gray-500 mt-1">
                <span>ãƒ¬ãƒ™ãƒ«: {micLevel}%</span>
                <span>{micLevel > 30 ? 'âœ… éŸ³å£°ã‚’æ¤œå‡ºä¸­' : micLevel > 5 ? 'âš ï¸ éŸ³ãŒå°ã•ã„' : 'âŒ éŸ³å£°ãªã— - ãƒã‚¤ã‚¯ã‚’ç¢ºèª'}</span>
              </div>
            </div>
          )}

          {isRecording && (
            <div className="mb-3 bg-red-50 border border-red-200 rounded p-3">
              <div className="flex items-center gap-2 text-sm text-red-700">
                <Mic className="w-4 h-4 animate-pulse" />
                <span>éŒ²éŸ³ä¸­... è©±ã—ã¦ãã ã•ã„</span>
              </div>
              {/* è¨ºæ–­ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ */}
              {sttEvents.length > 0 && (
                <div className="mt-2 pt-2 border-t border-red-200">
                  <div className="text-xs text-gray-600 font-mono space-y-0.5">
                    {sttEvents.map((evt, i) => (
                      <div key={i}>{evt}</div>
                    ))}
                  </div>
                  {restartDisplay > 0 && (
                    <div className="text-xs text-orange-600 mt-1">
                      âš ï¸ no-speechã§{restartDisplay}å›å†èµ·å‹•ï¼ˆéŸ³å£°ãŒå±Šã„ã¦ã„ãªã„å¯èƒ½æ€§ï¼‰
                    </div>
                  )}
                  {restartDisplay >= 3 && (
                    <div className="text-xs text-red-600 mt-1 font-medium">
                      ğŸ’¡ ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆã§éŸ³å£°ãŒæ‹¾ãˆã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆéŒ²éŸ³åœæ­¢â†’ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆï¼‰
                    </div>
                  )}
                </div>
              )}
            </div>
          )}

          {!isRecording && !isMicTesting && (
            <div className="mb-3 bg-blue-50 border border-blue-200 rounded p-3">
              <div className="flex items-center justify-between">
                <div className="flex items-center gap-2 text-sm text-blue-700">
                  <Mic className="w-4 h-4" />
                  <span>ã€ŒéŒ²éŸ³é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã‹ã€ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ <strong>Fnã‚­ãƒ¼ã‚’2å›</strong> ã§éŸ³å£°å…¥åŠ›</span>
                </div>
                <Button
                  onClick={startMicTest}
                  variant="outline"
                  size="sm"
                  className="text-xs px-2 py-1 ml-2 shrink-0"
                >
                  <Activity className="w-3 h-3 mr-1" />
                  ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆ
                </Button>
              </div>
            </div>
          )}

          <Textarea
            value={transcription + (interimText ? '\n' + interimText : '')}
            onChange={(e) => {
              if (!isRecording) setTranscription(e.target.value)
            }}
            placeholder="ã“ã“ã«ä¼šè©±å†…å®¹ã‚’å…¥åŠ›ï¼ˆéŒ²éŸ³ãƒœã‚¿ãƒ³ or Fn2å›ã§éŸ³å£°å…¥åŠ›ï¼‰..."
            className="flex-1 w-full p-4 border border-gray-300 rounded-lg resize-none focus:ring-2 focus:ring-blue-500 focus:border-blue-500 text-base"
            readOnly={isRecording}
          />
        </div>

        {/* å³ãƒ‘ãƒãƒ«: è¦ç´„ */}
        <div className="flex-1 p-6 flex flex-col">
          <h3 className="text-lg font-semibold mb-3">è¦ç´„ï¼ˆç·¨é›†å¯ï¼‰</h3>

          <div className="flex items-center gap-2 mb-3">
            <Select
              value={selectedTemplate}
              onValueChange={setSelectedTemplate}
              className="w-40 px-3 py-2 border border-gray-300 rounded"
            >
              <option value="soap">SOAPå½¢å¼</option>
              <option value="simple">ç°¡å˜è¦ç´„</option>
              <option value="detailed">è©³ç´°è¦ç´„</option>
            </Select>

            <Button
              onClick={generateSummary}
              disabled={isSummarizing || !transcription.trim()}
              className="bg-blue-500 hover:bg-blue-600 text-white px-4 py-2"
            >
              <FileText className="w-4 h-4 mr-1" />
              {isSummarizing ? 'è¦ç´„ä¸­...' : 'è¦ç´„ã™ã‚‹'}
            </Button>
          </div>

          <Textarea
            value={summary}
            onChange={(e) => setSummary(e.target.value)}
            placeholder="è¦ç´„çµæœãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™..."
            className="flex-1 w-full p-4 border border-gray-300 rounded-lg resize-none focus:ring-2 focus:ring-blue-500 focus:border-blue-500 text-base"
          />
        </div>
      </div>

      {/* ä¸‹éƒ¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ */}
      <div className="flex justify-end gap-3 p-4 border-t border-gray-200 bg-gray-50">
        <Button
          onClick={attachToSubKarte}
          disabled={!summary.trim()}
          className="bg-gray-500 hover:bg-gray-600 text-white px-6 py-2"
        >
          ã‚µãƒ–ã‚«ãƒ«ãƒ†ã«è²¼ä»˜
        </Button>
        <Button
          onClick={sendToActivity}
          disabled={!summary.trim()}
          className="bg-green-500 hover:bg-green-600 text-white px-6 py-2"
        >
          ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã«é€ä¿¡
        </Button>
      </div>
    </Modal>
  )
}
