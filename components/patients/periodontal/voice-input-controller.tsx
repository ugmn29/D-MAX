'use client'

import { useState, useRef, useCallback, useEffect } from 'react'
import { Button } from '@/components/ui/button'
import { Mic, MicOff, Volume2 } from 'lucide-react'
import {
  parseVoiceRecognition,
  type InputMode,
  type ParsedVoiceData,
} from '@/lib/utils/voice-recognition-parser'

// Web Speech APIå‹å®šç¾©
declare global {
  interface Window {
    SpeechRecognition: any
    webkitSpeechRecognition: any
  }
}

interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList
  resultIndex: number
}

interface SpeechRecognitionResultList {
  length: number
  item(index: number): SpeechRecognitionResult
  [index: number]: SpeechRecognitionResult
}

interface SpeechRecognitionResult {
  isFinal: boolean
  length: number
  item(index: number): SpeechRecognitionAlternative
  [index: number]: SpeechRecognitionAlternative
}

interface SpeechRecognitionAlternative {
  transcript: string
  confidence: number
}

interface VoiceInputControllerProps {
  currentMode: InputMode
  onModeChange: (mode: InputMode) => void
  onDataParsed: (data: ParsedVoiceData) => void
  isActive: boolean
  onActiveChange: (active: boolean) => void
}

export function VoiceInputController({
  currentMode,
  onModeChange,
  onDataParsed,
  isActive,
  onActiveChange,
}: VoiceInputControllerProps) {
  const [isRecording, setIsRecording] = useState(false)
  const [currentText, setCurrentText] = useState('')
  const [error, setError] = useState<string | null>(null)
  const [confidenceWarning, setConfidenceWarning] = useState<string | null>(null)

  const recognitionRef = useRef<any>(null)

  // å‡¦ç†æ¸ˆã¿ã®èªè­˜çµæœã‚’è¿½è·¡ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
  const lastProcessedTimeRef = useRef<number>(0)
  const lastProcessedTranscriptRef = useRef<string>('')

  // éŸ³å£°èªè­˜çµæœã‚’å‡¦ç†
  const handleRecognitionResult = useCallback((transcript: string, confidence: number, isFinal: boolean) => {
    const now = Date.now()
    console.log(`\nğŸ“ éŸ³å£°èªè­˜çµæœ (${isFinal ? 'ç¢ºå®š' : 'æš«å®š'}):`, {
      transcript,
      confidence,
      isFinal,
      timestamp: now,
      timeSinceLastProcess: now - lastProcessedTimeRef.current,
    })

    // æš«å®šçµæœã‚‚è¡¨ç¤ºï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼‰
    setCurrentText(transcript)

    // ç¢ºå®šçµæœã®ã¿å‡¦ç†
    if (!isFinal || !transcript.trim()) {
      console.log('  â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: æš«å®šçµæœã¾ãŸã¯ç©ºæ–‡å­—')
      return
    }

    // é‡è¤‡ãƒã‚§ãƒƒã‚¯: å®Œå…¨ã«åŒã˜transcriptã‚’400msä»¥å†…ã«å‡¦ç†ã—ãªã„
    // ã“ã‚Œã«ã‚ˆã‚ŠçœŸã®é‡è¤‡ï¼ˆinterimâ†’finalå¤‰æ›ã‚„çŸ­æ™‚é–“ã§ã®é‡è¤‡èªè­˜ï¼‰ã¯é˜²ãã¤ã¤ã€
    // ã‚†ã£ãã‚Šè©±ã—ãŸé€£ç¶šã—ãŸåŒã˜æ•°å­—ï¼ˆ500msä»¥ä¸Šã®é–“éš”ï¼‰ã¯è¨±å¯
    const timeSinceLastProcess = now - lastProcessedTimeRef.current
    if (
      transcript.trim() === lastProcessedTranscriptRef.current &&
      timeSinceLastProcess < 400
    ) {
      console.log('âš ï¸ é‡è¤‡æ¤œå‡º: åŒä¸€transcript (400msä»¥å†…)')
      console.log('  å‰å›:', lastProcessedTranscriptRef.current)
      console.log('  ä»Šå›:', transcript.trim())
      console.log('  çµŒéæ™‚é–“:', timeSinceLastProcess, 'ms')
      return
    }

    // å‡¦ç†æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯
    lastProcessedTimeRef.current = now
    lastProcessedTranscriptRef.current = transcript.trim()

    console.log('âœ… é‡è¤‡ãƒã‚§ãƒƒã‚¯é€šé - å‡¦ç†é–‹å§‹')
    console.log('  transcript:', transcript)
    console.log('  confidence:', confidence)
    console.log('  currentMode:', currentMode)

    // ä¿¡é ¼åº¦ãŒä½ã„å ´åˆã¯è­¦å‘Šã‚’è¡¨ç¤º
    if (confidence < 0.7) {
      setConfidenceWarning(`èªè­˜ã®ä¿¡é ¼åº¦ãŒä½ã‚ã§ã™ (${Math.round(confidence * 100)}%)`)
      setTimeout(() => setConfidenceWarning(null), 3000)
    } else {
      setConfidenceWarning(null)
    }

    // éŸ³å£°èªè­˜çµæœã‚’è§£æ
    const parsed = parseVoiceRecognition(transcript, currentMode, confidence)
    console.log('ğŸ” ãƒ‘ãƒ¼ã‚¹çµæœ:', {
      mode: parsed.mode,
      valuesCount: parsed.values.length,
      values: parsed.values,
      rawText: parsed.rawText,
      detectedMode: parsed.detectedMode,
    })

    // ãƒ¢ãƒ¼ãƒ‰å¤‰æ›´ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ
    if (parsed.detectedMode && parsed.detectedMode !== currentMode) {
      console.log('ğŸ”„ ãƒ¢ãƒ¼ãƒ‰å¤‰æ›´:', currentMode, '->', parsed.detectedMode)
      onModeChange(parsed.detectedMode)
    }

    // ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    console.log('ğŸ“¤ ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å‘¼ã³å‡ºã— - parsed.values.length:', parsed.values.length)
    onDataParsed(parsed)
  }, [currentMode, onModeChange, onDataParsed])

  // éŒ²éŸ³é–‹å§‹ï¼ˆWeb Speech APIï¼‰
  const startRecording = useCallback(() => {
    try {
      setError(null)

      // Web Speech APIã®å¯¾å¿œãƒã‚§ãƒƒã‚¯
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
      if (!SpeechRecognition) {
        setError('ãŠä½¿ã„ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚Chrome/Edgeã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚')
        return
      }

      const recognition = new SpeechRecognition()

      // è¨­å®š
      recognition.lang = 'ja-JP'
      recognition.continuous = true // é€£ç¶šèªè­˜
      recognition.interimResults = true // æš«å®šçµæœã‚‚å–å¾—
      recognition.maxAlternatives = 3 // ä»£æ›¿å€™è£œã‚‚å–å¾—

      // çµæœã‚¤ãƒ™ãƒ³ãƒˆ
      recognition.onresult = (event: SpeechRecognitionEvent) => {
        const results = event.results
        const result = results[event.resultIndex]
        const alternative = result[0]

        handleRecognitionResult(
          alternative.transcript,
          alternative.confidence,
          result.isFinal
        )
      }

      // ã‚¨ãƒ©ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ
      recognition.onerror = (event: any) => {
        console.error('éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:', event.error)
        if (event.error === 'no-speech') {
          console.log('âš ï¸ ç„¡éŸ³ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼ˆè‡ªå‹•ã§å†é–‹ã—ã¾ã™ï¼‰')
          // ç„¡éŸ³ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼ˆè‡ªå‹•ã§å†é–‹ã•ã‚Œã‚‹ï¼‰
        } else if (event.error === 'not-allowed') {
          setError('ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸ')
          setIsRecording(false)
          onActiveChange(false)
        } else {
          setError(`éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: ${event.error}`)
        }
      }

      // çµ‚äº†ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆè‡ªå‹•å†é–‹ï¼‰
      recognition.onend = () => {
        console.log('ğŸ”„ éŸ³å£°èªè­˜ãŒçµ‚äº†ã—ã¾ã—ãŸ')
        // éŒ²éŸ³ä¸­ãªã‚‰è‡ªå‹•ã§å†é–‹
        if (isRecording && recognitionRef.current) {
          console.log('â–¶ï¸ è‡ªå‹•å†é–‹')
          try {
            recognition.start()
          } catch (err) {
            console.error('å†é–‹ã‚¨ãƒ©ãƒ¼:', err)
          }
        }
      }

      // é–‹å§‹ã‚¤ãƒ™ãƒ³ãƒˆ
      recognition.onstart = () => {
        console.log('âœ… éŸ³å£°èªè­˜é–‹å§‹')
      }

      recognitionRef.current = recognition
      recognition.start()
      setIsRecording(true)
      setCurrentText('')
      onActiveChange(true)

      console.log('ğŸ¤ Web Speech API éŒ²éŸ³é–‹å§‹')
    } catch (err) {
      console.error('éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼:', err)
      setError('éŸ³å£°èªè­˜ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ')
    }
  }, [onActiveChange, handleRecognitionResult, isRecording])

  // éŒ²éŸ³åœæ­¢
  const stopRecording = useCallback(() => {
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop()
        recognitionRef.current = null
        console.log('â¹ï¸ éŸ³å£°èªè­˜åœæ­¢')
      } catch (err) {
        console.error('åœæ­¢ã‚¨ãƒ©ãƒ¼:', err)
      }
    }

    setIsRecording(false)
    onActiveChange(false)
  }, [onActiveChange])

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop()
        } catch (err) {
          // æ—¢ã«åœæ­¢ã—ã¦ã„ã‚‹å ´åˆã¯ç„¡è¦–
        }
      }
    }
  }, [])

  // ãƒ¢ãƒ¼ãƒ‰è¡¨ç¤ºå
  const getModeLabel = (mode: InputMode) => {
    switch (mode) {
      case 'ppd':
        return 'PPDæ¸¬å®š'
      case 'bop':
        return 'BOPè¨˜éŒ²'
      case 'mobility':
        return 'å‹•æºåº¦æ¸¬å®š'
    }
  }

  // ãƒ¢ãƒ¼ãƒ‰ã‚«ãƒ©ãƒ¼
  const getModeColor = (mode: InputMode) => {
    switch (mode) {
      case 'ppd':
        return 'bg-blue-100 border-blue-300 text-blue-800'
      case 'bop':
        return 'bg-red-100 border-red-300 text-red-800'
      case 'mobility':
        return 'bg-yellow-100 border-yellow-300 text-yellow-800'
    }
  }

  return (
    <div className="space-y-3 p-4 bg-white border border-gray-200 rounded-lg shadow-sm">
      {/* ãƒ˜ãƒƒãƒ€ãƒ¼ */}
      <div className="flex items-center justify-between">
        <div className="flex items-center space-x-2">
          {isRecording ? (
            <div className="flex items-center space-x-2">
              <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse" />
              <span className="text-sm font-medium text-red-600">éŒ²éŸ³ä¸­</span>
            </div>
          ) : (
            <div className="flex items-center space-x-2">
              <MicOff className="w-4 h-4 text-gray-400" />
              <span className="text-sm font-medium text-gray-500">å¾…æ©Ÿä¸­</span>
            </div>
          )}
        </div>

        <Button
          onClick={isRecording ? stopRecording : startRecording}
          variant={isRecording ? 'destructive' : 'default'}
          size="sm"
          className="min-w-[100px]"
        >
          {isRecording ? (
            <>
              <MicOff className="w-4 h-4 mr-2" />
              åœæ­¢
            </>
          ) : (
            <>
              <Mic className="w-4 h-4 mr-2" />
              éŒ²éŸ³é–‹å§‹
            </>
          )}
        </Button>
      </div>

      {/* ç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰è¡¨ç¤º */}
      <div className={`px-3 py-2 rounded-md border ${getModeColor(currentMode)}`}>
        <div className="flex items-center justify-between">
          <span className="text-sm font-semibold">
            ç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰: {getModeLabel(currentMode)}
          </span>
          <div className="flex gap-2">
            <Button
              onClick={() => onModeChange('ppd')}
              variant={currentMode === 'ppd' ? 'default' : 'outline'}
              size="sm"
              className="text-xs h-7"
              disabled={isRecording}
            >
              PPD
            </Button>
            <Button
              onClick={() => onModeChange('bop')}
              variant={currentMode === 'bop' ? 'default' : 'outline'}
              size="sm"
              className="text-xs h-7"
              disabled={isRecording}
            >
              BOP
            </Button>
            <Button
              onClick={() => onModeChange('mobility')}
              variant={currentMode === 'mobility' ? 'default' : 'outline'}
              size="sm"
              className="text-xs h-7"
              disabled={isRecording}
            >
              å‹•æºåº¦
            </Button>
          </div>
        </div>
      </div>

      {/* èªè­˜ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º */}
      {currentText && (
        <div className="px-3 py-2 bg-gray-50 border border-gray-200 rounded-md">
          <div className="flex items-start space-x-2">
            <Volume2 className="w-4 h-4 text-gray-500 mt-0.5" />
            <div className="flex-1">
              <p className="text-xs text-gray-500 mb-1">èªè­˜çµæœï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰:</p>
              <p className="text-sm font-medium text-gray-800">{currentText}</p>
            </div>
          </div>
        </div>
      )}

      {/* ä¿¡é ¼åº¦è­¦å‘Š */}
      {confidenceWarning && (
        <div className="px-3 py-2 bg-yellow-50 border border-yellow-200 rounded-md">
          <p className="text-sm text-yellow-700">{confidenceWarning}</p>
        </div>
      )}

      {/* ã‚¨ãƒ©ãƒ¼è¡¨ç¤º */}
      {error && (
        <div className="px-3 py-2 bg-red-50 border border-red-200 rounded-md">
          <p className="text-sm text-red-600">{error}</p>
        </div>
      )}

      {/* ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰ */}
      {!isRecording && !isActive && (
        <div className="text-xs text-gray-500 space-y-1 pt-2 border-t border-gray-200">
          <p className="font-semibold">ğŸ“ ä½¿ã„æ–¹:</p>
          <ul className="list-disc list-inside space-y-0.5 ml-2">
            <li>PPDãƒ¢ãƒ¼ãƒ‰: ã€Œ3, 4, 3, 3, 2, 2...ã€ã¨æ•°å€¤ã‚’é€£ç¶šã§èª­ã¿ä¸Šã’</li>
            <li>BOPãƒ¢ãƒ¼ãƒ‰(1ç‚¹æ³•): ã€ŒBOP 31, 34, 45ã€ã¨æ­¯ç•ªå·ã‚’èª­ã¿ä¸Šã’</li>
            <li>BOPãƒ¢ãƒ¼ãƒ‰(4/6ç‚¹æ³•): ã€ŒBOP 37è¿‘å¿ƒé ¬å´, 41é å¿ƒèˆŒå´ã€ã¨ä½ç½®ã‚‚æŒ‡å®š</li>
            <li>å‹•æºåº¦ãƒ¢ãƒ¼ãƒ‰: ã€Œå‹•æºåº¦ 16ç•ª2åº¦, 36ç•ª1åº¦ã€ã¨èª­ã¿ä¸Šã’</li>
            <li>ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ: ã€ŒBOPã€ã€Œå‹•æºåº¦ã€ã¨è¨€ã†ã ã‘ã§è‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ</li>
          </ul>
        </div>
      )}
    </div>
  )
}
